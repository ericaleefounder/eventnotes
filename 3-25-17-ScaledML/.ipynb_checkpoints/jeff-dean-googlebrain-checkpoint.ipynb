{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google brain team : research impact \n",
    "\n",
    "* Since 2012, published > 130 \n",
    "\n",
    "### Main Research Areas\n",
    " * Gen ML, Algos and Techniques \n",
    " * C Sys for ML\n",
    " * NL Understanding\n",
    " * perception\n",
    " * Healthcare\n",
    " * Robotics\n",
    " * Music and Art Generation\n",
    "    [Link] (research.googleblog.com/2017/01/the-google-brain-team-looking-back-on.html)\n",
    "    \n",
    "### Experiment = hella days\n",
    "* Turnaround Time and Research Productiviyt\n",
    "*Minutes, Hours - Interactive research, Instat gratification!\n",
    "* 1-3 days - tolerable. \n",
    "* 1-4 weeks high value experiemnts only. \n",
    "* Progress stalls.\n",
    "> 1 month - don't even try\n",
    "\n",
    "## TF Overview: Computation is a dataflow graph - with state\n",
    "// Jeff's comments on infographic\n",
    "* state you maintain, update at end of graph\n",
    "* computational garphs - abstract - map onto 1 or mutliple computing devices\n",
    "* Terminology: 3-4D arrays - tensors\n",
    "\n",
    "### Same mechanisim supports large distributed systems\n",
    "* Computation spread across hundreds of distributed systems \n",
    "\n",
    "### What Did We Build TensorFlow?\n",
    "* Wanted system that was flexible, scalba,e and production-ready\n",
    "* DistBelief, our first system, was good on two of these, but lacked flexibilty\n",
    "* Most existing open source packages were good on 2 of 3, but not all 3\n",
    "\n",
    "### Just-In-Time Compilation via XLA, Accerlated Lineary Algebra compilerTf graphi go in\n",
    "* Optimized and specialized assembly comes out. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo: Inspirct JTI Code in TF iPython shell\n",
    "    * Qualcomm snapdragon for embedded devices\n",
    "    \n",
    "    Computers can now see large implications for healthcare\n",
    "    \n",
    "    // Lily's group\n",
    "    Medical imaging\n",
    "    * Using similar model for detecting diabetic retinopahty in retinal images\n",
    "    arxiv.org/abs/1703.02442\n",
    "    [Long link] (https://research.googleblog.com/2017/03/assisting-pathologists-in-detecting.html) \n",
    "    \n",
    "    Pathology - localized pathology images (cancer)\n",
    "    Extremely large images ( > 100kx100k pixels)\n",
    "    Multiscale problem - need detail a well as context\n",
    "    \n",
    "## Multiscale model\n",
    "* detail <--> context\n",
    "* resembles micrscope magnifications\n",
    "* Jeff's comments: using inception v3, pretrained on imagenet\n",
    "    prediction on cancer\n",
    "    *   detecting breast cancr metastass in lymp nodes\n",
    "    \n",
    "    biopsy image, ground truth (from pathologist) model precdiction,early results\n",
    "    \n",
    "    model pre\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other NLP \n",
    "* Sequence-to-sequence model: machine translation\n",
    "* Sutskever and Vinyals & Le  NIPS 2014 \n",
    "* At inference time, beam search to chose most probaly over possible output seq\n",
    "// Sequence to Sequence model applied to Google Translate\n",
    "\n",
    "Infog: Google Neural Machine Translation Model\n",
    "\n",
    "[Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](http://www.arxiv.org/abs/1609.08144)\n",
    "* One model replica: one machine w/ 8 GPUs\n",
    "* Encoder LSTMs -> attnt \n",
    "* Decoder LSTMs -> Softmax\n",
    "\n",
    "[Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation](http://research.google.blog.com/2016/09/a-neural-network-for-machine.html)\n",
    "\n",
    "[Zero-Shot Translation with Googleâ€™s Multilingual Neural Machine Translation System]\n",
    "(https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html)\n",
    "\n",
    "Bigger models, but sparsely activated \n",
    "Motivation: want huge model capacity\n",
    "\n",
    "Infographic: \n",
    "* Per-Ex Routing\n",
    "* Feed data into gating network\n",
    "* MoE layers \n",
    "* Sparse, routed to a number of experts\n",
    "\n",
    "Outrageously Large Neural Networks: The Sparsely-gated Mixture-of-Experts Layer\n",
    "http://openreview.net/pdf?id=B2ckMDqlg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
